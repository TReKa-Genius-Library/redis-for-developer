# 9. Redis 자체의 고가용성 기능인 센티널

- 모니터링 : 마스터, 복제본 인스턴스의 상태를 실시간으로 확인한다.
- 자동 fail-over : 비정상 상태를 감지하여 정상 상태의 복제본 중 하나를 마스터로 승격시킨다.
- 인스턴스 구성 정보 안내 : Redis의 endpoint 변경할 필요 없도록 client에세 현재 구성에서의 마스터 정보를 알려준다.

## 9.1 분산 시스템으로 동작하는 센티널
센티널 자체의 SPOF 문제를 막기 위하여 최소 3대 이상일 때 정상적으로 동작할 수 있도록 설계되어있다.
`quorum` 이라는 개념을 사용하여 오탐을 줄인다. 이는 일종의 다수결 투표와 같은것 같다.
3대의 센티널이 있는 상황에서 2대가 마스터 노드가 문제 있다 생각하면 fail-over과정이 진행된다.

## 9.2 센티널 인스턴스 배치
기본적으로 3개의 물리적으로 분리된 장소의 서버 사용 권장
각 서버에 Redis와 Sentinel 설치 권장

## 9.3 센티널 인스턴스 실행하기
센티널에 접속시 센티널이 모니터링 하고 있는 Master와 replica 노드의 정보, 복제본을 함께 모니터링하고 있는 다른 센티널 인스턴스에 대한 정보를 확인할 수 있다.
다만, Redis 인스턴스가 갖고있는 데이터는 확인 불가

```
SENTINEL master <master-name>
```

- num-other-sentinels : 마스터를 모니터링하고 있는 다른 센티널의 정보를 나타낸다.
- flags : 마스터의 상태를 나타낸다. 마스터가 비 정상인 경우 s_down, o_down 으로 값이 변경됨
- num-slaves : 마스터에 연결된 복제본의 개수

다음 명령어를 통해 복제본의 자세한 정보 확인 가능

```
SENTINEL replicas master-test
```


다음 명령어를 통해 복제본의 자세한 정보 확인 가능

```
SENTINEL sentinels master-test
```


다음 명령어를 통하여 센티널 인스턴스가 설정한 쿼럼 값보다 큰지 확인할 수 있다.
```
SENTINEL chquorum
```

예를 들어 3대의 센티널중 1대가 문제가 생긴경우 알아보자.
쿼럼값이 2인 경우 정상 센티널의 수가 2대이기 때문에 센티널은 정상이라 판단하며, 다음과 같다.
```
SENTINEL chquorum master-check
OK 2 usable Sentinels. Quorum and failover authorization can be reached
```

이때 1대가 더 종료된다면, 설정한 쿼럼(2)값 보다 작아지게 되며, 비정상 적인 센티널의 상태
```
SENTINEL chquorum master-check
(error) NOQUORUM 1 ~~
```

## 9.4 센티널 운영하기
### 9.4.1) 페스워드 인증
하나의 복제 그룹에서 requirepasss와 masterauth 값은 모든 노드에서 동일하게 설정해야 한다.

### 9.4.2) 복제본 우선순위
모든 레디스 인스턴스에는 replica-priority 라는 파라미터가 있다.
센티널은 fail-over시 replica-priority 라는 우선순위 노드를 확인하며, 해당값이 가장 작은 노드를 마스터로 선출한다.

### 9.4.3) 센티널 초기화
센티널은 장애가 발생한 노드도 계속 모니터링을 시도한다.
주기적으로 해당 노드에 PING을 보내 상태를 확인한다. 해당 노드의 모니터링을 중단 하려면 SENTINEL RESET 커맨드를 사용해 센티널 인스턴스의 상태 정보를 초기화 해야 한다.
```
SENTINEL RESET <master name>
```

## 9.5 센티널의 자동 Failover 과정
### 9.5.1) 마스터 장애 상황 감지
- down-after-milliseconds 파라미터에 지정된 값 이상 동안 마스터에 보낸 PING에 대해 유효한 응답을 받지 못하면 마스터가 다운됐다고 판단.
- 기본 30초이며, 마스터가 29초마다 응답시 정상이라 판단

### 9.5.2) sdown, odwon 실패 상태로 전환
- 센티널 노드에서 마스터 인스턴스에 대한 응답을 늦게 받으면 -> 일단 sdown(subjectly down) 으로 변경
- 이후 다른 노드들에세 장애 사실 전파
- 다른 센티널들은 해당 마스터 서버의 장애를 인지했는지 여부를 응답
- 쿼럼값 이상의 센티널 노드가 장애를 인지했다면 -> odwon(objectly down) 으로 변경

이렇게 sdwon -> odwon 과정을 위해 다른 센티널 노드에게 물어보는 작업은 master에만 해당됨
복제본들은 sdwon만되고 끝남.

### 9.5.3) 애포크 값 증가
각 마스터에서 발생한 fail-over의 버전을 관리. 에포크는 증가하는 숫자값으로, 처음으로 fail-over가 일어날 때의 에포크 값은 1이된다.

### 9.5.4) 리더 선출
> 과반수와 쿼럼
> sdown -> odown으로 변경하기 위해서는 쿼럼 값 이상의 센티널의 동의가 필요하다.
> 실제 fail-over 실행시 쿼럼 값이 아니라 실제 센티널 개수 중 과반 수 이상의 센티널의 동의를 얻어야만 센티널 리버가 선출된다.


### 9.5.5) 복제본으로 부터의 마스터 선출
1. redis.conf 파일에 명시된 replica-priority가 낮은 본제본 선택
2. 마스터로부터 더 많은 데이터를 수신한 복제본
3. 2번 조건까지 동일하다면, runID가 사전 순으로 작은 복제본

## 9.6 스플릿 브레인 현상
네트워크 파티션 이슈로 인해 분산 환경의 데이터 저장소가 끊어지고, 끊긴 두 부분이 각각을 정상적인 서비스라고 인식하는 현상.

간단히 말하면, 단순 네트워크 연결의 불안정인데,
1. 마스터 노드와의 네트워크 연결 장애
2. 이를 센티널이 장애로 인지하여 복제본을 마스터로 승격
3. 문제는 단지 노드 간 네트워크 단절이 일어난경우, 하나의 복제본에 2개의 마스터가 생김

네트워크 복구시 기존 마스터는 새롭게 승격된 마스터의 복제본으로 연결된다.
이때 복제본으로 연결되는 과정에서 복제본 노드의 데이터를 모두 삭제 -> 기존 데이터 모두 유실



