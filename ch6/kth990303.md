### 메시징 큐와 이벤트 스트림
- 메시징 큐
  - producer-consumer
  - **방향성**: 2개의 서비스에 같은 메시지를 보내야할 경우, 생산자는 2개의 각각 다른 메시징 큐에 데이터 push
  - **영속성**: 소비자가 데이터를 읽을 경우 큐에서 데이터 삭제
- 이벤트 스트림
  - publisher-subscriber
  - **방향성**: 2개의 서비스에 같은 메시지를 보내야할 경우, 발행자는 스트림 특정 저장소에 보내고 구독자들은 스트림에서 pull
    - 🙋🏻‍♂️ 중요하진 않지만, p.156 에 스트림 쪽에서 `생산자, 소비자`라는 단어로 되어있는데 `발행자, 구독자`로 쓰는 것이 혼동의 여지가 없으리라 판단하여 요약본에선 `발행자/구독자`로 용어 바꿔서 작성함.
      - `생산자/소비자`, `발행자/구독자` 용어는 자주 혼용된다고 책에서도 언급돼있어서 큰 문제는 없어보임. 
  - **영속성**: 구독자가 읽어간 데이터는 바로 삭제되지 않고, 저장소 설정에 따라 특정 기간동안 저장될 수 있음.
 
- MQ는 빠른 속도로 메시지를 전달하는 데에, 스트림은 빠른 속도로 메시지를 저장하는 데에 초점에 맞춰져있다고 한다.
  - MQ: The focus is on the high-speed delivering of the messages to the subscribers, not the saving of the messages.
  - Stream: The focus is on the high-speed storing of the events, appending them to the end of the stream, not the high-speed delivering of the events to the recipients. 
  - 출처: https://www.linkedin.com/pulse/differences-between-message-queue-event-stream-frank-lieu

### 레디스의 pub/sub
- 레디스의 pub/sub은 매우 가볍기 때문에 최소한의 메시지 전달 기능만 제공한다.
- `발행자`는 메시지를 채널로 보낼 수 있을 뿐, **어떤 구독자가 메시지를 읽어가는지, 정상적으로 모든 구독자에게 메시지가 전달됐는지 확인할 수 없다.**
- `구독자` 또한 메시지를 받을 수 있지만 해당 메시지가 **언제 어떤 발행자에 의해 생성됐는지 등의 메타데이터는 알 수 없다.** (p.159)
  -  🙋🏻‍♂️ 데이터 내에 발행자 정보를 담아주는 것으로 어느 정도 해소할 수 있음.
  -  장애로 인해 메시지를 받지 못했더라도 그 사실을 알기 힘드므로 정합성이 중요한 데이터는 적절치 않을 수 있음.
- 키워드
  - publish: 데이터 전파 (ex. `publish hello world`: hello 채널에 world 메시지 전파)
  - subscribe: 특정 채널 구독 (ex. `subscribe event1 event2`: event1, event2 채널 동시 구독 / `psubscribe mail-*`: 접두사가 mail인 채널 동시 구독)
    - subscribe, psubscirbe 커맨드로 동시에 구독할 경우, 메시지를 2번 수신하게 됨.
  - spublish: 노드의 복제본에만 메시지 전파 (sharded pub/sub)
    - 참고: https://charsyam.wordpress.com/2022/04/18/%EC%9E%85-%EA%B0%9C%EB%B0%9C-redis-7-x-%EC%97%90%EC%84%9C%EC%9D%98-shardedpubsub/
    - 클러스터 환경에 유리
   
### 레디스 list를 메시징 큐로 사용
- 사용자의 캐시가 이미 존재하는지의 유무를 애플리케이션에서 확인하는 과정 없이, 모든 로직을 레디스에서 제어할 수 있기 때문에 불필요한 확인 과정을 줄여 성능을 향상시킬 수 있게 된다. (p.166)
  - 🙋🏻‍♂️ 정합성 중요성이 적은 데이터 + 성능 이슈가 존재할 수 있는 데이터는 레디스에 책임을 위임해도 괜찮을 거 같다는 생각이 들었다.
- 블로킹 기능 사용 가능 - 타임아웃 값을 설정하여 해당 값만큼 기다리고 넘으면 nil 반환

### 레디스 stream 
- 데이터 저장
  - 카프카: 토픽 내의 파티션 내에서만 id unique
    - 토픽을 생성한 후, 프로듀서로 데이터를 보냄. 
  - 레디스 stream: id timestamp 관련 unique 값으로 중복되지 않음
    - 별도로 토픽 생성과정 필요 없으며, XADD 커맨드로 데이터를 스트림으로 보냄.
- 데이터 조회
  - 카프카: 특정 토픽 실시간 리스닝
    - `from-beginning`: 카프카 저장돼있는 모든 데이터를 처음부터 읽겠다는 의미, 새 이벤트가 들어올 때까지 계속 토픽 리스닝
  - 레디스 스트림
    - `XREAD`: 실시간 리스닝
      - `XREAD BLOCK n STERAMS Email m`: 들어오는 데이터가 없더라도 최대 n ms(0일 경우 무한대)만큼 연결 유지하며 대기, Email 스트림에 저장된 데이터 중 id가 m($의 경우 스트림에 저장된 최대 id)보다 큰 값 읽어오라.
     
### 소비자와 소비자그룹
- 팬아웃
  - 카프카: 같은 토픽을 여러 소비자가 읽어가게끔
  - 레디스 stream: `XREAD` 커맨드를 여러 소비자가 수행하게끔
- 데이터 순서 보장
  - 카프카: 유니크 키가 파티션 내에서만 보장 - 소비자가 여러 파티션에서 토픽을 읽어갈때 순서보장되지 않음.
    - 소비자그룹 이용  
  - 레디스 stream: 고유 id - 순서 항상 보장
    - 래디스 stream에서의 소비자 그룹은, 다른 소비자가 아직 읽지 않은 데이터만을 읽어가도록 할 때 사용
      - `XGROUP CREATE Email EmailServiceGroup $`: Email stream을 읽어가는 EmailServiceGroup 소비자그룹 생성하여 현재 시점 이후의 데이터부터 읽어오라.
      - `XGROUP CREATE EmailServiceGroup emailService1 COUNT 1 STERAMS Email`: EmailServiceGroup 소비자그룹의 emailService1 소비자는 Email stream에 있는 1개의 메시지를 읽어오라.
        - 다른 소비자에게 읽히지 않은 데이터가 없다면 nil 반환
- ACK와 보류 리스트
  - 카프카: `__consumer_offsets` 토픽에 파티션별 오프셋 관리
  - 레디스: 각 소비자뱔로 pending list 생성하고, 어떤 데이터를 읽어갔는지 인지
    - `XACK`를 이용해 소비자가 데이터를 읽어갔는지 확인할 수 있음.
    - 메시지 보증 전략
      - `at most once`: 무조건 한번 전송받으면 소비자는 처리전에 ack 보냄.
      - `at least once`: 메시지 처리하고 나서 ack 보냄.
      - `exactly once`: 무조건 한번 전송받았다는 걸 보장한다는 의미. 추가적인 기능 필요할 것 (set 등 추가 자료구조 활용)
        - 사실상 불가능에 가까운 얘기인 것 같음. 참고: https://devs0n.tistory.com/74
        - 장애가 한번도 발생하지 않을 거라는 얘기와 동급인 거 같기도? 
 
